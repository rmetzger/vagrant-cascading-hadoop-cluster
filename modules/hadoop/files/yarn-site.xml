<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
  <property>
      <name>yarn.resourcemanager.address</name>
      <value>master.local:8032</value>
  </property>
  <property>
      <name>yarn.resourcemanager.scheduler.address</name>
      <value>master.local:8030</value>
  </property>
  <property>
      <name>yarn.resourcemanager.resource-tracker.address</name>
      <value>master.local:8031</value>
  </property>
  <property>
      <name>yarn.resourcemanager.admin.address</name>
      <value>master.local:8033</value>
  </property>
  <property>
      <name>yarn.acl.enable</name>
      <value>false</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
    <description>shuffle service that needs to be set for Map Reduce to run </description>
  </property>
  <property>
      <name>yarn.web-proxy.address</name>
      <value>master.local:8100</value>
  </property>
  <property>
      <name>yarn.log-aggregation-enable</name>
      <value>true</value>
  </property>
  <property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>1</value>
  </property>
  <property>
    <name>yarn.nodemanager.vmem-pmem-ratio</name>
    <value>5</value>
  </property>
  <!-- 
    Make sure that yarn.scheduler.minimum-allocation-mb <= yarn.nodemanager.resource.memory-mb
  -->
  <property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>128</value>
    <description>
      Number of missed scheduling opportunities after which the CapacityScheduler
      attempts to schedule rack-local containers.
      Typically this should be set to number of nodes in the cluster, By default is setting
      approximately number of nodes in one rack which is 40.
    </description>
  </property>

  <!-- 
    Set the amount of memory that is available on each nodeManager for a container.
  -->
  <property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>400</value>
  </property>

</configuration>
